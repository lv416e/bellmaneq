{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cake Eating Problem\n",
    "\n",
    "The **Cake Eating Problem** is the simplest dynamic programming model.\n",
    "A household has a cake of initial size $x$ and must decide how much to consume\n",
    "each period. The cake is not replenished \u2014 whatever is consumed today is gone forever.\n",
    "\n",
    "The Bellman equation is:\n",
    "\n",
    "$$V(x) = \\max_{0 \\leq c \\leq x} \\left\\{ u(c) + \\beta \\, V(x - c) \\right\\}$$\n",
    "\n",
    "where:\n",
    "- $x$ is the current cake size (state variable),\n",
    "- $c$ is consumption (control variable),\n",
    "- $u(c)$ is the per-period utility from consumption,\n",
    "- $\\beta \\in (0, 1)$ is the discount factor.\n",
    "\n",
    "Despite its simplicity, this problem illustrates the key trade-off in all of dynamic\n",
    "programming: consuming more today yields immediate utility, but reduces the cake\n",
    "available for future consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bellmaneq\n",
    "from bellmaneq.viz import plot_convergence\n",
    "from bellmaneq.viz.econ import plot_cake_eating\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving with Default Parameters\n",
    "\n",
    "We solve the Cake Eating Problem using `bellmaneq.solve_cake_eating()`,\n",
    "which applies value iteration on the discretized Bellman equation.\n",
    "The default parameters use $\\beta = 0.95$ with log utility ($\\sigma = 1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bellmaneq.solve_cake_eating(discount=0.95)\n",
    "\n",
    "print(f'Converged: {result.converged}')\n",
    "print(f'Iterations: {result.iterations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Function and Optimal Consumption\n",
    "\n",
    "The value function $V(x)$ is concave and increasing in the cake size.\n",
    "The optimal consumption policy $c^*(x)$ prescribes a constant fraction\n",
    "of the cake to eat each period (for log utility).\n",
    "\n",
    "The 45-degree line on the consumption plot helps identify whether the agent\n",
    "eats the entire cake immediately ($c = x$) or saves some for later ($c < x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_cake_eating(result.get_cake_grid(), result.get_values(), result.get_policy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Statics: Discount Factor $\\beta$\n",
    "\n",
    "The discount factor $\\beta$ governs how patient the agent is:\n",
    "- A **low** $\\beta$ (e.g., 0.8) means the agent heavily discounts the future and consumes more today.\n",
    "- A **high** $\\beta$ (e.g., 0.99) means the agent is very patient and saves more of the cake.\n",
    "\n",
    "We compare the value function and consumption policy across three values of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for beta in [0.8, 0.9, 0.99]:\n",
    "    r = bellmaneq.solve_cake_eating(discount=beta)\n",
    "    axes[0].plot(r.get_cake_grid(), r.get_values(), label=f'\\u03b2={beta}')\n",
    "    axes[1].plot(r.get_cake_grid(), r.get_policy(), label=f'\\u03b2={beta}')\n",
    "\n",
    "axes[0].set_xlabel('Cake Size (x)')\n",
    "axes[0].set_ylabel('Value V(x)')\n",
    "axes[0].set_title('Value Function')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Cake Size (x)')\n",
    "axes[1].set_ylabel('Consumption c*(x)')\n",
    "axes[1].set_title('Consumption Policy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Effect of Discount Factor', fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "\n",
    "Value iteration converges geometrically at rate $\\beta$. The convergence history\n",
    "shows the sup-norm distance $\\|V_{k+1} - V_k\\|_\\infty$ at each iteration.\n",
    "The plot below uses the baseline result ($\\beta = 0.95$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_convergence(result.get_convergence_history())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
